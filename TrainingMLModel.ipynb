{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import scipy.misc\n",
    "from scipy import misc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "for i in range(1,10):\n",
    "    arr = scipy.misc.imread('imgs/imgs/'+str(i)+'.jpg',flatten='True',mode='L')\n",
    "    \n",
    "    #arr = scipy.misc.imresize(arr,size=(96,96))\n",
    "    #scipy.misc.imshow(arr)\n",
    "    #arr = arr.reshape((1,200,200))\n",
    "    x.append(arr)\n",
    "x1 = np.asarray(x)\n",
    "y = [0,0,0,0,1,1,1,0,1]\n",
    "y1 = np.asarray(y)\n",
    "y1 = y1.reshape(9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21264, 2304)\n",
      "(21264, 1)\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('fer2013/fer2013.csv')\n",
    "newx = x.loc[x['emotion'].isin((3,4,6))]\n",
    "X = newx['pixels']\n",
    "Y = newx['emotion']\n",
    "t = []\n",
    "for i in X:\n",
    "    t.append(map(int, i.split(' ')))\n",
    "XFull = np.asarray(t)\n",
    "Y = np.asarray(Y)\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "print XFull.shape\n",
    "print Y.shape\n",
    "Y[Y==3] = 0\n",
    "Y[Y==4] = 1\n",
    "Y[Y==6] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(811, 2304)\n",
      "(811, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "happy = []\n",
    "folder = './happy_faces_cropped'\n",
    "suffix ='jpg'\n",
    "for fn in os.listdir(folder):\n",
    "    if(fn.endswith(suffix)):\n",
    "        arr = scipy.misc.imread(folder+'/'+str(fn),flatten='True')\n",
    "        arr = arr.flatten()\n",
    "        happy.append(arr)\n",
    "happyFinal = np.asarray(happy)\n",
    "happyLabel = np.zeros(len(happy))\n",
    "happyLabel = happyLabel.reshape(happyLabel.shape[0],1)\n",
    "print happyFinal.shape\n",
    "print happyLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 2304)\n",
      "(671, 1)\n",
      "[ 2.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "neutral = []\n",
    "folder = './neutral_faces_cropped'\n",
    "suffix ='jpg'\n",
    "for fn in os.listdir(folder):\n",
    "    if(fn.endswith(suffix)):\n",
    "        arr = scipy.misc.imread(folder+'/'+str(fn),flatten='True')\n",
    "        arr = arr.flatten()\n",
    "        neutral.append(arr)\n",
    "neutralFinal = np.asarray(neutral)\n",
    "neutralLabel = np.zeros(len(neutral))\n",
    "for i in range(len(neutralLabel)):\n",
    "    neutralLabel[i] = 2\n",
    "neutralLabel = neutralLabel.reshape(neutralLabel.shape[0],1)\n",
    "print neutralFinal.shape\n",
    "print neutralLabel.shape\n",
    "print neutralLabel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2304)\n",
      "(200, 1)\n",
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "sad = []\n",
    "folder = './sad_faces_cropped'\n",
    "suffix ='jpg'\n",
    "for fn in os.listdir(folder):\n",
    "    if(fn.endswith(suffix)):\n",
    "        arr = scipy.misc.imread(folder+'/'+str(fn),flatten='True')\n",
    "        arr = arr.flatten()\n",
    "        sad.append(arr)\n",
    "sadFinal = np.asarray(sad)\n",
    "sadLabel = np.ones(len(sad))\n",
    "sadLabel = sadLabel.reshape(sadLabel.shape[0],1)\n",
    "print sadFinal.shape\n",
    "print sadLabel.shape\n",
    "print sadLabel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22946, 2304)\n",
      "(22946, 1)\n"
     ]
    }
   ],
   "source": [
    "XFull = np.concatenate((XFull,happyFinal,neutralFinal,sadFinal),axis = 0)\n",
    "Y = np.concatenate((Y,happyLabel,neutralLabel,sadLabel),axis = 0)\n",
    "print XFull.shape\n",
    "print Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XFull,Y,test_size=0.3, random_state=42)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1,48,48).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1,48,48).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(128, 7, 7, border_mode='valid', input_shape=(1, 48, 48), activation='relu'))#54\n",
    "    #\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, activation='relu'))#50\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))#25\n",
    "    model.add(Convolution2D(64, 5, 5, activation='relu'))#21\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))#19\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))#9\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    #\tmodel.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (7, 7), padding=\"valid\", activation=\"relu\", input_shape=(1, 48, 48...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\")`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\")`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16062 samples, validate on 6884 samples\n",
      "Epoch 1/15\n",
      "298s - loss: 1.0794 - acc: 0.4280 - val_loss: 1.0957 - val_acc: 0.4208\n",
      "Epoch 2/15\n",
      "298s - loss: 1.0681 - acc: 0.4329 - val_loss: 1.0591 - val_acc: 0.4362\n",
      "Epoch 3/15\n",
      "299s - loss: 1.0062 - acc: 0.4978 - val_loss: 0.9297 - val_acc: 0.5601\n",
      "Epoch 4/15\n",
      "300s - loss: 0.9060 - acc: 0.5671 - val_loss: 0.8773 - val_acc: 0.5960\n",
      "Epoch 5/15\n",
      "300s - loss: 0.8587 - acc: 0.5971 - val_loss: 0.8634 - val_acc: 0.5978\n",
      "Epoch 6/15\n",
      "299s - loss: 0.8316 - acc: 0.6170 - val_loss: 0.8413 - val_acc: 0.6119\n",
      "Epoch 7/15\n",
      "300s - loss: 0.7978 - acc: 0.6366 - val_loss: 0.8249 - val_acc: 0.6206\n",
      "Epoch 8/15\n",
      "299s - loss: 0.7703 - acc: 0.6529 - val_loss: 0.8139 - val_acc: 0.6331\n",
      "Epoch 9/15\n",
      "299s - loss: 0.7398 - acc: 0.6700 - val_loss: 0.8098 - val_acc: 0.6291\n",
      "Epoch 10/15\n",
      "300s - loss: 0.7275 - acc: 0.6810 - val_loss: 0.7938 - val_acc: 0.6429\n",
      "Epoch 11/15\n",
      "300s - loss: 0.6852 - acc: 0.7033 - val_loss: 0.7868 - val_acc: 0.6447\n",
      "Epoch 12/15\n",
      "300s - loss: 0.6587 - acc: 0.7146 - val_loss: 0.8046 - val_acc: 0.6456\n",
      "Epoch 13/15\n",
      "300s - loss: 0.6266 - acc: 0.7333 - val_loss: 0.8432 - val_acc: 0.6326\n",
      "Epoch 14/15\n",
      "300s - loss: 0.5882 - acc: 0.7519 - val_loss: 0.8251 - val_acc: 0.6460\n",
      "Epoch 15/15\n",
      "300s - loss: 0.5548 - acc: 0.7686 - val_loss: 0.8660 - val_acc: 0.6469\n",
      "Baseline Error: 35.31%\n"
     ]
    }
   ],
   "source": [
    "model = larger_model()\n",
    "#model.load_weights(\"weights4_layers_updated_11layer_9700_wts.h5\",by_name=False)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=15, batch_size=300, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "model.save(\"weights4_layers_Jokebot_50_alldataepochs_new.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take test data and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPred = numpy.fromfile('dataset/test_x.bin', dtype='uint8')\n",
    "xPred = xPred.reshape((20000,96,96))\n",
    "xPred[xPred<255] = 0\n",
    "xPred = xPred/ 255\n",
    "#xPred[xPred<1] = -1\n",
    "xPred=xPred.reshape(xPred.shape[0],1,96,96).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = x1.reshape(x1.shape[0], 1,96,96).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "arr = misc.imread('Images/000001.jpg') # 640x480x3 array\n",
    "print arr.shape\n",
    "print arr[20, 30] # 3-vector for a pixel\n",
    "print arr[20, 30, 1] # green value for a pixel\n",
    "print type(arr)\n",
    "#scipy.misc.imshow(arr)\n",
    "#arr = arr.flatten()\n",
    "print arr.shape\n",
    "#arr = arr.reshape((600,600,3))\n",
    "\n",
    "#arr[arr<255] = 0\n",
    "arr = scipy.misc.imread('Images/000001.jpg',flatten='True',mode='L')\n",
    "scipy.misc.imshow(arr)\n",
    "print arr.shape\n",
    "print arr[0:100]\n",
    "\n",
    "arr = scipy.misc.imresize(arr,size=(200,200))\n",
    "#arr = arr.flatten()\n",
    "#scipy.misc.imshow(arr)\n",
    "print arr.shape\n",
    "print arr[0:100]\n",
    "arr = arr.reshape((1,200,200))\n",
    "#print arr[0:100]\n",
    "#print arr.shape\n",
    "#scipy.misc.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#tf.python.control_flow_ops = tf\n",
    "import scipy.misc # to visualize only\n",
    "x = numpy.fromfile('Images/000001.bin', dtype='uint8')\n",
    "print x.shape\n",
    "\n",
    "x = x.reshape((3,600,600))\n",
    "#x[x<255] = 0\n",
    "\n",
    "scipy.misc.imshow(x[0]) # to visualize only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "#import h5py\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = arr\n",
    "y = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pixels = x.shape[0] * x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y=y.as_matrix()\n",
    "x1 = x1.reshape(x1.shape[0], 1,200,200).astype('float32')\n",
    "#X_test = X_test.reshape(X_test.shape[0], 1,60,60).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the input data has been transformed to the form 1,60,60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('dataset/train_y.csv')\n",
    "y=y['Prediction']\n",
    "y=y.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=42)\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1,60,60).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1,60,60).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalise the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the model with the different convolutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Layer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(32, 7, 7, border_mode='valid', input_shape=(1, 60, 60), activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "#\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(32, 5, 5, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(64, 5, 5, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(128, 5, 5, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "#\tmodel.add(Dense(256, activation='relu'))\n",
    "\tmodel.add(Dense(256, activation='relu'))\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Layer Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(64, 7, 7, border_mode='valid', input_shape=(1, 60, 60), activation='relu'))#54\n",
    "#\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(64, 5, 5, activation='relu'))#50\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#25\n",
    "\tmodel.add(Convolution2D(64, 5, 5, activation='relu'))#21\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#19\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#9\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "#\tmodel.add(Dense(256, activation='relu'))\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-Layer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(64, 3, 3, border_mode='valid', input_shape=(1, 60, 60), activation='relu'))#58\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#56\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#28\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#26\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#24\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#10\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#8\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#4\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#2\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#1\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu',W_regularizer=l2(0.01)))\n",
    "\tmodel.add(Dense(50, activation='relu',W_regularizer=l2(0.01)))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = larger_model()\n",
    "#model.load_weights(\"weights4_layers_updated_11layer_9700_wts.h5\",by_name=False)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "#model.save(\"weights4_layers_updated_11layer_part3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take test data and predict output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPred = numpy.fromfile('dataset/test_x.bin', dtype='uint8')\n",
    "xPred = xPred.reshape((20000,60,60))\n",
    "xPred[xPred<255] = 0\n",
    "xPred = xPred/ 255\n",
    "#xPred[xPred<1] = -1\n",
    "xPred=xPred.reshape(xPred.shape[0],1,60,60).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.misc.imshow(xPred[19962]) # to visualize only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can save the model and reuse it for future purposes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"weights4_layers_updated_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"weights4_layers_updated_11layer_part3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"weights4_layers_updated_11layer_9704_wts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights4_layers_wts.h5\",by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xPred.shape\n",
    "predictions = model.predict(X_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalpred=[]\n",
    "for i in predictions:\n",
    "    finalpred.append([j for j,z in enumerate(i) if z == max(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newy_test = []\n",
    "for i in y_test:\n",
    "    newy_test.append([j for j,z in enumerate(i) if z == max(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648024404416\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for i in range(len(finalpred)):\n",
    "    if(finalpred[i] == newy_test[i]):\n",
    "        count+=1\n",
    "\n",
    "print (count * 1.0)/len(finalpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [1], [1], [0], [0], [2], [0], [2], [0], [1], [1], [1], [2], [0], [2], [0], [0], [0], [2], [1], [0], [1], [1], [0], [0], [1], [1], [0], [2], [0]]\n",
      "[[0], [0], [0], [0], [0], [2], [0], [0], [0], [0], [1], [1], [0], [0], [1], [1], [0], [0], [0], [1], [1], [1], [0], [0], [0], [1], [0], [0], [2], [0]]\n"
     ]
    }
   ],
   "source": [
    "print newy_test[0:30]\n",
    "print finalpred[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output into a file as per the required format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictionFileName = \"Predictions4layers_updated_11layer_9700.csv\"\n",
    "result = pd.DataFrame(columns=('Id','Prediction'))\n",
    "count = 0\n",
    "for i in finalpred:\n",
    "    y = \"%d\"%count\n",
    "    value = \"%d\"%i[0]\n",
    "    result.loc[count]=[y,value]\n",
    "    count+=1\n",
    "result.to_csv(predictionFileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"finalpred_modified.csv\", \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(finalpred[0:15000])\n",
    "\n",
    "with open(\"finalpred0.8_modified1.csv\", \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(finalpred[15000:20000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
